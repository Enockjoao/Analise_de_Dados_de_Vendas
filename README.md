# Pipeline de AnÃ¡lise de Dados de Vendas ğŸš€âœ¨ğŸ“Š

---

## **DescriÃ§Ã£o do Projeto** ğŸ“œğŸ› ï¸ğŸ’¡

Este projeto implementa uma pipeline de dados para realizar o processo de **ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carregamento)** de um conjunto de dados de vendas. O objetivo principal Ã© transformar um arquivo CSV bruto em dados organizados e armazenados em um banco de dados SQLite, prontos para anÃ¡lise e visualizaÃ§Ã£o.

Este projeto Ã© ideal para entender o ciclo de vida dos dados em pipelines e pode ser expandido para casos reais em aplicaÃ§Ãµes de engenharia de dados. ğŸ”ğŸ“ˆğŸŒŸ

---

## **Estrutura do Projeto** ğŸ—‚ï¸âš™ï¸ğŸ”§

A estrutura segue boas prÃ¡ticas de organizaÃ§Ã£o para facilitar a colaboraÃ§Ã£o e manutenÃ§Ã£o:

```
data-pipeline/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Arquivos CSV originais
â”‚   â”‚   â””â”€â”€ sales_data.csv  # Arquivo bruto de vendas
â”‚   â””â”€â”€ processed/          # Dados limpos e transformados
â”œâ”€â”€ database/               # Banco de dados SQLite
â”‚   â””â”€â”€ sales.db            # Banco criado pela pipeline
â”œâ”€â”€ scripts/                # Scripts ETL
â”‚   â”œâ”€â”€ extract.py          # ExtraÃ§Ã£o dos dados do CSV
â”‚   â”œâ”€â”€ transform.py        # Limpeza e transformaÃ§Ã£o dos dados
â”‚   â”œâ”€â”€ load.py             # Carregamento dos dados no SQLite
â”‚   â””â”€â”€ utils.py            # FunÃ§Ãµes auxiliares para anÃ¡lise e visualizaÃ§Ã£o
â”œâ”€â”€ main.py                 # Script principal para orquestrar a pipeline
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â””â”€â”€ LICENSE                 # LicenÃ§a do projeto
```

---

## **Tecnologias Utilizadas** ğŸ’»ğŸ“šğŸ”¬

- **Linguagem:** Python 3.8+
- **Bibliotecas:**
  - `pandas`: ManipulaÃ§Ã£o e anÃ¡lise de dados.
  - `sqlite3`: InteraÃ§Ã£o com banco de dados SQLite.
  - `sqlalchemy`: Alternativa para consultas SQL avanÃ§adas.
  - `matplotlib` e `seaborn`: VisualizaÃ§Ã£o de dados (prontos para futuras anÃ¡lises).

---

## **ConfiguraÃ§Ã£o do Ambiente** ğŸ–¥ï¸ğŸ› ï¸ğŸ“¦

1. **Clone o repositÃ³rio:**

   ```bash
   git clone https://github.com/seu-usuario/data-pipeline.git
   cd data-pipeline
   ```

2. **Crie e ative um ambiente virtual (opcional, mas recomendado):**

   ```bash
   python -m venv venv
   source venv/bin/activate      # No Windows: venv\Scripts\activate
   ```

3. **Instale as dependÃªncias:**

   ```bash
   pip install -r requirements.txt
   ```

---

## **Como Usar** ğŸƒâ€â™‚ï¸ğŸ“‚âš™ï¸

1. **Adicione os dados brutos:**
   Coloque o arquivo CSV de vendas (`sales_data.csv`) na pasta `data/raw/`.

2. **Execute a pipeline:**

   ```bash
   python main.py
   ```

3. **Verifique os resultados:**
   - O banco de dados `sales.db` serÃ¡ criado na pasta `database/`.
   - Os dados transformados estarÃ£o disponÃ­veis na tabela `sales`. ğŸ¯ğŸ“Šâœ…

---

## **Funcionamento da Pipeline** ğŸ”âš™ï¸ğŸ“ˆ

### **1. ExtraÃ§Ã£o** ğŸ“¥ğŸ“‹ğŸ’¾
O script `extract.py` lÃª o arquivo CSV bruto e converte os dados em um DataFrame do pandas.

### **2. TransformaÃ§Ã£o** ğŸ› ï¸ğŸ§¹ğŸ”„
O script `transform.py` aplica as seguintes transformaÃ§Ãµes:
- Remove entradas nulas.
- Converte colunas para os tipos apropriados:
  - `price`: `float`
  - `quantity`: `int`
  - `date`: `datetime`
- Garante que todos os dados estejam consistentes e prontos para anÃ¡lise.

### **3. Carregamento** ğŸ“¤ğŸ“‚ğŸ—„ï¸
O script `load.py` carrega os dados transformados em um banco de dados SQLite, criando a tabela `sales` se ela ainda nÃ£o existir.

---

## **Exemplo de ExpansÃ£o** ğŸš€ğŸŒğŸ”§

Este projeto pode ser expandido com:
- **Dashboards:** Use ferramentas como Tableau ou Power BI conectadas ao SQLite para criar grÃ¡ficos e relatÃ³rios.
- **AutomatizaÃ§Ã£o:** Integre o pipeline com Airflow ou Prefect para execuÃ§Ã£o agendada.
- **ConexÃ£o com APIs:** Extraia dados diretamente de APIs externas em vez de arquivos CSV.

---


